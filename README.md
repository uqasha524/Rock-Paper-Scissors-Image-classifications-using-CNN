# âœŠâœ‹âœŒï¸ Rock-Paper-Scissors Image Classification Using CNN

## ğŸ“Œ Project Overview  
This project classifies hand gestures into **Rock**, **Paper**, or **Scissors** categories using **Convolutional Neural Networks (CNNs)**.  

To better understand performance differences, we first implemented traditional **Machine Learning (ML)** and **Artificial Neural Network (ANN)** approaches. These methods were limited in generalization capability for unseen image data, as they rely heavily on manually extracted features.  

This served as a **baseline comparison** to highlight the superior performance of CNNs, which can automatically learn spatial hierarchies from raw images. CNNs outperformed ML and ANN models significantly in terms of accuracy and robustness.

---

<img src="Images/Stone-Paper-Scissors.png" alt="Stone Paper Scissors Game Demo" width="600"/>

---

## ğŸ—‚ï¸ Dataset Overview  
We used an image dataset containing labeled hand gesture images:
- `rock/` â€“ images of a closed fist  
- `paper/` â€“ images of an open hand  
- `scissors/` â€“ images of two extended fingers  

## ğŸ—‚ï¸ Dataset Overview  
We used an image dataset containing labeled hand gesture images:
- `rock/` â€“ images of a closed fist  
- `paper/` â€“ images of an open hand  
- `scissors/` â€“ images of two extended fingers  

> âš ï¸ The dataset is not included in this repository due to size limits.  
> Please use your own or download a public Rock-Paper-Scissors image dataset and structure it as shown above.  
> ğŸ“© *If you would like access to the dataset used in this project, feel free to contact me at [uqashazahid@gmail.com](mailto:uqashazahid@gmail.com).*

---

Dataset/
â”œâ”€â”€ train/
â”‚ â”œâ”€â”€ rock/
â”‚ â”œâ”€â”€ paper/
â”‚ â””â”€â”€ scissors/
â”œâ”€â”€ validation/
â”‚ â”œâ”€â”€ rock/
â”‚ â”œâ”€â”€ paper/
â”‚ â””â”€â”€ scissors/
â””â”€â”€ test/
â”œâ”€â”€ rock/
â”œâ”€â”€ paper/
â””â”€â”€ scissors/

---

## ğŸ“ Files Overview  

The `CNN/` folder contains all files related to the Convolutional Neural Network implementation:

- **`cnn.ipynb`** â€“ This Jupyter Notebook includes all code for:
  - Training the CNN model  
  - Performing real-time predictions  
  - Evaluating the model  
  - Visualizing performance metrics  

- **Saved Keras model files** â€“ After training, the best-performing models (based on accuracy) are saved in this folder for later use.

- **Image Augmentation** â€“ We applied various image augmentation techniques (e.g., rotation, zoom, flip) to artificially expand the training dataset. This helped demonstrate how:
  - Augmentation increases dataset diversity  
  - Accuracy improves  
  - Overfitting is reduced  

These files showcase both the process and results of training robust image classification models using CNNs.


